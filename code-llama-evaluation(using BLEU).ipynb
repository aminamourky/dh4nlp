{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import transformers\nfrom datasets import load_dataset\nfrom nltk.translate.bleu_score import sentence_bleu","metadata":{"execution":{"iopub.status.busy":"2024-03-18T11:14:45.865352Z","iopub.execute_input":"2024-03-18T11:14:45.865783Z","iopub.status.idle":"2024-03-18T11:14:51.747423Z","shell.execute_reply.started":"2024-03-18T11:14:45.865748Z","shell.execute_reply":"2024-03-18T11:14:51.746595Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Load CoNaLa dataset\n#dataset = load_dataset(\"grail_qa\", \"conala\")  # Using Hugging Face Datasets for convenience\ndataset = load_dataset(\"neulab/conala\")","metadata":{"execution":{"iopub.status.busy":"2024-03-18T11:14:51.748567Z","iopub.execute_input":"2024-03-18T11:14:51.749384Z","iopub.status.idle":"2024-03-18T11:14:53.827104Z","shell.execute_reply.started":"2024-03-18T11:14:51.749348Z","shell.execute_reply":"2024-03-18T11:14:53.826214Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07c461524ad9470abeef9cdfb638348d"}},"metadata":{}}]},{"cell_type":"code","source":"print(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T11:14:53.828220Z","iopub.execute_input":"2024-03-18T11:14:53.828475Z","iopub.status.idle":"2024-03-18T11:14:53.833876Z","shell.execute_reply.started":"2024-03-18T11:14:53.828454Z","shell.execute_reply":"2024-03-18T11:14:53.832976Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['question_id', 'intent', 'rewritten_intent', 'snippet'],\n        num_rows: 2379\n    })\n    test: Dataset({\n        features: ['question_id', 'intent', 'rewritten_intent', 'snippet'],\n        num_rows: 500\n    })\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2024-03-18T11:14:53.835886Z","iopub.execute_input":"2024-03-18T11:14:53.836158Z","iopub.status.idle":"2024-03-18T11:14:53.842236Z","shell.execute_reply.started":"2024-03-18T11:14:53.836135Z","shell.execute_reply":"2024-03-18T11:14:53.841310Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Create pipeline for Code Llama\nmodel = transformers.pipeline(\n    \"text-generation\",\n    model=\"codellama/CodeLlama-7b-Instruct-hf\",\n    torch_dtype=torch.float32,\n    device_map=\"auto\"  # Use GPU if available\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T11:14:53.843247Z","iopub.execute_input":"2024-03-18T11:14:53.843504Z","iopub.status.idle":"2024-03-18T11:16:00.610467Z","shell.execute_reply.started":"2024-03-18T11:14:53.843482Z","shell.execute_reply":"2024-03-18T11:16:00.609596Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-03-18 11:14:54.716872: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-18 11:14:54.716928: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-18 11:14:54.720586: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb9349ce8250435ba79c1ee720f41a42"}},"metadata":{}}]},{"cell_type":"code","source":"# Iterate through testing set\nbleu_scores = []\nfor example in dataset[\"test\"]:\n    \n    prompt = example[\"intent\"]  \n\n    # Reference code for BLEU score calculation\n    reference_code = example[\"snippet\"]  # Expected code snippet\n\n    # Generate code using the model pipeline\n    output = model(prompt, max_length=50)\n    #output = model(prompt, max_length=20, batch_size=1, truncation=True)\n    generated_text = output[0].get(\"generated_text\")  # Access generated text\n    \n    '''\n    if generated_text is None:\n        print(\"Generated text not found in model output:\", output)\n        continue\n\n    # Ensure generated_text is a string\n    if not isinstance(generated_text, str):\n        print(\"Generated text is not a string:\", generated_text)\n        continue\n    '''\n\n    # Calculate BLEU score\n    bleu = sentence_bleu([reference_code.split()], generated_text.split())\n    bleu_scores.append(bleu)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print average BLEU score\nprint(f\"Average BLEU score: {sum(bleu_scores) / len(bleu_scores)}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-18T12:24:38.307779Z","iopub.execute_input":"2024-03-18T12:24:38.308479Z","iopub.status.idle":"2024-03-18T12:24:38.313166Z","shell.execute_reply.started":"2024-03-18T12:24:38.308447Z","shell.execute_reply":"2024-03-18T12:24:38.312273Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Average BLEU score: 0.0952474061356062\n","output_type":"stream"}]}]}